[Smoothing]
# All Required
# Meaning probability smoothing
beta=10000
lambda=0.00001
# Rate at which Lambda decreases over time - "c" is in first paper concerning LTs and NDs 
power=1
# Alignment probability smoothing
alpha=20
epsilon=0.01

[Similarity]
# All Required
# Similarity measure used for evaluation
# Accepted Types: COS, JSD, EUC, AP. See constants.py for details.
simtype=COS
# Threshold to determine whether a word has been acquired/learned
theta=0.7

[Features]
# All optional
dummy=false
forget=false
forget-decay=0
novelty=false
novelty-decay=0
# Required. If ACT, forget must be true.
# Accepted Types: SUM, ACT, DEC_SUM. See constants.py for details.
# DEC_SUM requires a forget decay, as it is a "forgetting" based assoc type.
assoc-type=SUM

# to grow a semantic network or not
semantic-network=false
hub-type=hub-categories-prob-random
hub-num=20

[Statistics]
# Optional
#traceword=test
# Required, Record stats flag
stats=true
# Required, Record context related stats flag
context-stats=false
age-of-exposure-norm=100
# The following are Required if stats=true, disregarded otherwise. 
# Accepted Tags: ALL, N, V, OTH. See constants.py for details.
tag1=ALL
# Optional if tag1 is anything but ALL
#tag2=
#tag3=
# Prefixes of the properties files to be created while recording statistics
word-props-name=word_props_itr_
time-props-name=time_props_itr_
context-props-name=context_props


[Other]
# All optional
# Minimum number of occurrences a word must have before it can be considered learned
minfreq=1
# Number of iterations after which properties will be written to files
record-iterations=-1
# Maximum number of time steps the model will run for
maxtime=2000000
#15000
# Maximum number of words the model will learn
maxlearned=-1
